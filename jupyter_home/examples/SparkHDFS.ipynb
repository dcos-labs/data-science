{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark with HDFS\n",
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "from pyspark.sql.types import DoubleType, IntegerType\n",
    "from pyspark.sql.functions import lit, udf\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier as RF, LogisticRegression as LR\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ith_(v, i):\n",
    "    try:\n",
    "        return float(v[i])\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "ith = udf(ith_, DoubleType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from HDFS\n",
    "Load data and cast strings to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(x1=0.8171528684921276, x2=0.24987197734186745, y=1), Row(x1=-0.5184817239482779, x2=0.7912845668866769, y=0), Row(x1=1.0296384467915982, x2=-0.1947061822599957, y=0), Row(x1=-0.20666705157261883, x2=-0.8435154054082349, y=1), Row(x1=0.39311970409126296, x2=-0.6849043070449546, y=1), Row(x1=0.1671154341000823, x2=-0.7596441718756154, y=1), Row(x1=0.124653679176714, x2=-0.7204281190897744, y=1), Row(x1=-0.7800525661517679, x2=-0.6838101624023487, y=0), Row(x1=-1.0101224339480892, x2=0.12096830580580976, y=0), Row(x1=-0.04453222401484804, x2=-1.0130259056466904, y=0)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_load = spark.read.csv('hdfs:///circle.csv', header=\"true\")\n",
    "df_load = df_load.withColumn(\"x1\", df_load[\"x1\"].cast(DoubleType()))\n",
    "df_load = df_load.withColumn(\"x2\", df_load[\"x2\"].cast(DoubleType()))\n",
    "df_load = df_load.withColumn(\"y\", df_load[\"y\"].cast(IntegerType()))\n",
    "\n",
    "print(df_load.count())\n",
    "df_load.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pipeline\n",
    "Assign features and dependent variable.<br>\n",
    "Build random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1998347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(probability=DenseVector([0.9999, 0.0001]), label=0.0), Row(probability=DenseVector([0.9999, 0.0001]), label=0.0), Row(probability=DenseVector([0.9999, 0.0001]), label=0.0), Row(probability=DenseVector([0.9998, 0.0002]), label=0.0), Row(probability=DenseVector([0.9998, 0.0002]), label=0.0), Row(probability=DenseVector([0.9999, 0.0001]), label=0.0), Row(probability=DenseVector([0.9998, 0.0002]), label=0.0), Row(probability=DenseVector([0.9999, 0.0001]), label=0.0), Row(probability=DenseVector([1.0, 0.0]), label=0.0), Row(probability=DenseVector([0.9999, 0.0001]), label=0.0)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureCols = ['x1', 'x2']\n",
    "assembler_features = VectorAssembler(inputCols=featureCols, outputCol='features')\n",
    "labelIndexer = StringIndexer(inputCol='y', outputCol=\"label\")\n",
    "\n",
    "dfX = [assembler_features, labelIndexer]\n",
    "pipeline = Pipeline(stages=dfX)\n",
    "\n",
    "allData = pipeline.fit(df_load).transform(df_load)\n",
    "\n",
    "trainingData, testData = allData.randomSplit([0.8, 0.2], seed=0)\n",
    "rf = RF(labelCol='label', featuresCol='features', numTrees=50)\n",
    "fit = rf.fit(trainingData)\n",
    "transformed = fit.transform(testData)\n",
    "results = transformed.select(['probability', 'label'])\n",
    "\n",
    "print(results.count())\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create truth table\n",
    "Extract probability from Dense Vector<br>\n",
    "Create group by using Spark. This scales, but may not with python dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of sample accuracy = 0.8260552346514394\n",
      "Out of sample precision = 0.7529563089959204\n",
      "Out of sample recall = 0.970014586956696\n",
      "Out of sample F1 = 0.8478130475480792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   label  prediction   count\n",
       "0    0.0           0  682523\n",
       "1    0.0           1  317672\n",
       "2    1.0           0   29930\n",
       "3    1.0           1  968222"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = results.select(['label', (ith(\"probability\", lit(1)) > 0.5).cast('integer').alias('prediction') ])\n",
    "truth_table = validation.groupBy(['label', 'prediction']).count().orderBy(['label', 'prediction'])\n",
    "\n",
    "tt = truth_table.toPandas()\n",
    "tp = tt[((tt.label == 1) & (tt.prediction == 1))]['count'].values[0]\n",
    "fp = tt[((tt.label == 0) & (tt.prediction == 1))]['count'].values[0]\n",
    "fn = tt[((tt.label == 1) & (tt.prediction == 0))]['count'].values[0]\n",
    "tn = tt[((tt.label == 0) & (tt.prediction == 0))]['count'].values[0]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fp + fn)\n",
    "precision = tp/(tp + fp)\n",
    "recall = tp/(tp + fn)\n",
    "f1 = (2.0 * precision*recall)/(precision+recall)\n",
    "\n",
    "print(\"Out of sample accuracy =\", accuracy)\n",
    "print(\"Out of sample precision =\", precision)\n",
    "print(\"Out of sample recall =\", recall)\n",
    "print(\"Out of sample F1 =\", f1)\n",
    "tt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aside\n",
    "To make the model a bit of a challenege the dependent variable was a circle inside a circle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Sample](data_sample.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing to do with Spark or HDFS, but here is a fun way to demonstrate how domain knowledge and improved data/transformation can be more valuable than model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of sample accuracy = 0.9770945686609983\n",
      "Out of sample precision = 0.9765407105036412\n",
      "Out of sample recall = 0.9776276559081182\n",
      "Out of sample F1 = 0.9770838809160841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   label  prediction   count\n",
       "0    0.0           0  976753\n",
       "1    0.0           1   23442\n",
       "2    1.0           0   22331\n",
       "3    1.0           1  975821"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_load = df_load.withColumn(\"x3\", (df_load[\"x1\"]**2 + df_load[\"x2\"]**2).cast(DoubleType()))\n",
    "\n",
    "featureCols = ['x1', 'x2', 'x3']\n",
    "assembler_features = VectorAssembler(inputCols=featureCols, outputCol='features')\n",
    "labelIndexer = StringIndexer(inputCol='y', outputCol=\"label\")\n",
    "\n",
    "dfX = [assembler_features, labelIndexer]\n",
    "pipeline = Pipeline(stages=dfX)\n",
    "\n",
    "allData = pipeline.fit(df_load).transform(df_load)\n",
    "\n",
    "trainingData, testData = allData.randomSplit([0.8, 0.2], seed=0)\n",
    "lr = LR(labelCol='label', featuresCol='features')\n",
    "fit = lr.fit(trainingData)\n",
    "transformed = fit.transform(testData)\n",
    "results = transformed.select(['probability', 'label'])\n",
    "\n",
    "validation = results.select(['label', (ith(\"probability\", lit(1)) > 0.5).cast('integer').alias('prediction') ])\n",
    "truth_table = validation.groupBy(['label', 'prediction']).count().orderBy(['label', 'prediction'])\n",
    "\n",
    "tt = truth_table.toPandas()\n",
    "tp = tt[((tt.label == 1) & (tt.prediction == 1))]['count'].values[0]\n",
    "fp = tt[((tt.label == 0) & (tt.prediction == 1))]['count'].values[0]\n",
    "fn = tt[((tt.label == 1) & (tt.prediction == 0))]['count'].values[0]\n",
    "tn = tt[((tt.label == 0) & (tt.prediction == 0))]['count'].values[0]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fp + fn)\n",
    "precision = tp/(tp + fp)\n",
    "recall = tp/(tp + fn)\n",
    "f1 = (2.0 * precision*recall)/(precision+recall)\n",
    "\n",
    "print(\"Out of sample accuracy =\", accuracy)\n",
    "print(\"Out of sample precision =\", precision)\n",
    "print(\"Out of sample recall =\", recall)\n",
    "print(\"Out of sample F1 =\", f1)\n",
    "tt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Granted this data is clearly rigged and the knowledge of how it's rigged is exploited for the transform. <br>\n",
    "It's worth noting, however, because many real business problems can also be solved with greater intuition more than more data or model tuning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - PySpark",
   "language": "python",
   "name": "apache_toree_pyspark"
  },
  "language_info": {
   "codemirror_mode": "text/x-ipython",
   "file_extension": ".py",
   "mimetype": "text/x-ipython",
   "name": "python",
   "pygments_lexer": "python",
   "version": "3.6.6\n"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
